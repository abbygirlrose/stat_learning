---
title: "Exploring the Relationship Between Joe Biden Ratings and Gender"
author: "Abby Bergman"
date: "11/6/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dplyr)
library(modelr)
library(broom)
library(rsample)
library(magrittr)
library(caret )
```

```{r, warning=FALSE, message=FALSE}
#Do women display higher feeling thermometer ratings for Joe Biden than men?

#get the data
library(readr)
biden <- read_csv("data/biden.csv")

biden$female <- factor(biden$female, levels=c(0,1), labels=c("Male", "Female"))


```

```{r, inlude = FALSE}
#Estimate a basic (single variable) linear regression model of the relationship between gender and feelings towards Joe Biden.

bid_mod <- lm(biden ~ female, data = biden)
```

```{r, echo = FALSE}
#Calculate predicted values, graph the relationship between the two variables using the predicted values, and determine whether there appears to be a significant relationship.

grid <- biden %>% 
  data_grid(female, biden) 


grid <- grid %>% 
  add_predictions(bid_mod)

#make new df with predicted values
pred <- augment(bid_mod, type.predict = "response")

ggplot(data = pred, aes(x = female, group = 1)) +
  geom_line(aes(y=.fitted)) +
  labs(title = "Graph of Gender vs Opinion of Joe Biden", y = "Opinion of Biden", x = "Gender") 

summary(bid_mod)
```
As shown above, the relationship between feelings towards biden and gender is significant with a p-value of less than .05 (p =   9.03e-08). The coefficient is 5.833 for the variable "female".


```{r}
#Build the best predictive linear regression model of attitudes towards Joe Biden given the variables you have available. In this context, “best” is defined as the model with the lowest MSE. Compare at least three different model formulations (aka different combinations of variables). Use 10-fold cross-validation to avoid a biased estimate of MSE.

biden_age_pid <- lm(biden ~ age+pid, data = biden)

biden_pid <- lm(biden ~ pid, data = biden)

biden_age <- lm(biden ~ age, data = biden)

#for age+pid 
# function to generate assessment statistics for titanic model

holdout_results_pid_age <- function(splits) {
  # Fit the model to the training set
  mod <- glm(biden ~ age+pid, data = analysis(splits))

  # Save the heldout observations
  holdout <- assessment(splits)

  # `augment` will save the predictions with the holdout data set
  res <- augment(mod, newdata = holdout) %>% 
    mutate(.resid = biden -.fitted)

  # Return the assessment data set with the additional columns
  res
}

#for pid
# function to generate assessment statistics for titanic model

holdout_results_pid <- function(splits) {
  # Fit the model to the training set
  mod <- glm(biden ~ pid, data = analysis(splits))

  # Save the heldout observations
  holdout <- assessment(splits)

  # `augment` will save the predictions with the holdout data set
  res <- augment(mod, newdata = holdout) %>% 
    mutate(.resid = biden -.fitted)

  # Return the assessment data set with the additional columns
  res
}

#for age
# function to generate assessment statistics for titanic model

holdout_results_age <- function(splits) {
  # Fit the model to the training set
  mod <- glm(biden ~ age, data = analysis(splits))

  # Save the heldout observations
  holdout <- assessment(splits)

  # `augment` will save the predictions with the holdout data set
  res <- augment(mod, newdata = holdout) %>% 
    mutate(.resid = biden -.fitted)

  # Return the assessment data set with the additional columns
  res
}

#remove nas
biden_new <- biden%>%
  na.omit()
  

# CV for pid and age
pid_age_cv10 <- vfold_cv(data = biden_new, v = 10) %>%
  mutate(results = map(splits, holdout_results_pid_age),
         mse = map_dbl(results, ~ mean(.$.resid ^ 2)))
mean(pid_age_cv10$mse, na.rm = TRUE)


#CV for pid
pid_cv10 <- vfold_cv(data = biden_new, v = 10) %>%
  mutate(results = map(splits, holdout_results_pid),
         mse = map_dbl(results, ~ mean(.$.resid ^ 2)))
mean(pid_cv10$mse, na.rm = TRUE)

#CV for age
age_cv10 <- vfold_cv(data = biden_new, v = 10) %>%
  mutate(results = map(splits, holdout_results_age),
         mse = map_dbl(results, ~ mean(.$.resid ^ 2)))
mean(age_cv10$mse, na.rm = TRUE)

```

The model that takes into account both party ID and age has the lowest error rate. The error for the model with only party ID was only slightly higher  but the model that only took age into account was much higher (see values in results above). 

```{r}
#what happens if we include gender in the model?
biden_age_pid_gender <- lm(biden ~ age+pid+female, data = biden)

holdout_results_age_pid_gender <- function(splits) {
  # Fit the model to the training set
  mod <- glm(biden ~ age+pid+female, data = analysis(splits))

  # Save the heldout observations
  holdout <- assessment(splits)

  # `augment` will save the predictions with the holdout data set
  res <- augment(mod, newdata = holdout) %>% 
    mutate(.resid = biden -.fitted)

  # Return the assessment data set with the additional columns
  res
}

age_pid_gender_cv10 <- vfold_cv(data = biden_new, v = 10) %>%
  mutate(results = map(splits, holdout_results_age_pid_gender),
         mse = map_dbl(results, ~ mean(.$.resid ^ 2)))
mean(age_pid_gender_cv10$mse, na.rm = TRUE)
```
Here we see that when we include the gender variable in the model, the error rate is lowered to 397.7192 so this is a better model.